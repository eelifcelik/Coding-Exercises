# -*- coding: utf-8 -*-
"""celciustofahrenheit.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1cTgo-amfv8Ty7XtxywkbxMP3ZyhXtDEd
"""

import tensorflow as tf

import numpy as np
import logging
logger = tf.get_logger()
logger.setLevel(logging.ERROR)

celcius_q = np.array([-40, -10, 0, 8, 15, 22, 38], dtype=float)
fahrenheit_a = np.array([-40, 14, 32, 46, 59, 72, 100], dtype=float)

for i,c in enumerate(celcius_q):
  print("{} degree celcius = {} degree fahrenheit".format(c,fahrenheit_a[i]))

l0 = tf.keras.layers.Dense(units=1, input_shape =[1])

model = tf.keras.Sequential([l0])

model.compile(loss = 'mean_squared_error',
              optimizer= tf.keras.optimizers.Adam(0.1))

history = model.fit(celcius_q, fahrenheit_a, epochs=500, verbose=False)
print("Model Finished training")

import matplotlib.pyplot as plt
plt.xlabel('Epoch Number')
plt.ylabel("Loss Magnetude")
plt.plot(history.history['loss'])

print(model.predict([100.0]))

print("These are layer variables : {}" .format(l0.get_weights()))

l0 = tf.keras.layers.Dense(units=4, input_shape =[1])
l1 = tf.keras.layers.Dense(units=4)
l2 = tf.keras.layers.Dense(units=1)

model = tf.keras.Sequential([l0,l1,l2])

model.compile(loss = 'mean_squared_error',
              optimizer= tf.keras.optimizers.Adam(0.1))

history = model.fit(celcius_q, fahrenheit_a, epochs=500, verbose=False)
print("Model Finished training")

print(model.predict([100.0]))